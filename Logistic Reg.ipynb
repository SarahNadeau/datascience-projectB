{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, preprocessing, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import cleaned dataset from last project\n",
    "data = pd.DataFrame.from_csv('cleaned.csv')\n",
    "\n",
    "# convert all features to categorical integer values\n",
    "#enc = LabelEncoder()\n",
    "#for i in data.columns:\n",
    "    #data[i] = enc.fit_transform(data[i])\n",
    "\n",
    "BsmtQual = data['BsmtQual']\n",
    "encodings = {'Ex': 6, 'Gd': 5, 'TA': 4, 'Fa': 3, 'Po': 2, 'NP' :1}\n",
    "for key in encodings:\n",
    "    BsmtQual = BsmtQual.replace(key, encodings[key])\n",
    "    data['BsmtQual'] = BsmtQual\n",
    "    \n",
    "ExterQual = data['ExterQual']\n",
    "encodings = {'Ex': 6, 'Gd': 5, 'TA': 4, 'Fa': 3, 'Po': 2, 'NP' :1}\n",
    "for key in encodings:\n",
    "    ExterQual = ExterQual.replace(key, encodings[key])\n",
    "    data['ExterQual'] = ExterQual\n",
    "    \n",
    "ExterCond = data['ExterCond']\n",
    "encodings = {'Ex': 6, 'Gd': 5, 'TA': 4, 'Fa': 3, 'Po': 2, 'NP' :1}\n",
    "for key in encodings:\n",
    "    ExterCond = ExterCond.replace(key, encodings[key])\n",
    "    data['ExterCond'] = ExterCond\n",
    "    \n",
    "BsmtCond = data['BsmtCond']\n",
    "encodings = {'Ex': 6, 'Gd': 5, 'TA': 4, 'Fa': 3, 'Po': 2, 'NP' :1}\n",
    "for key in encodings:\n",
    "    BsmtCond = BsmtCond.replace(key, encodings[key])\n",
    "    data['BsmtCond'] = BsmtCond\n",
    "    \n",
    "KitchenQual = data['KitchenQual']\n",
    "encodings = {'Ex': 6, 'Gd': 5, 'TA': 4, 'Fa': 3, 'Po': 2, 'NP' :1}\n",
    "for key in encodings:\n",
    "    KitchenQual = KitchenQual.replace(key, encodings[key])\n",
    "    data['KitchenQual'] = KitchenQual\n",
    "    \n",
    "GarageQual = data['GarageQual']\n",
    "encodings = {'Ex': 6, 'Gd': 5, 'TA': 4, 'Fa': 3, 'Po': 2, 'NP' :1}\n",
    "for key in encodings:\n",
    "    GarageQual = GarageQual.replace(key, encodings[key])\n",
    "    data['GarageQual'] = GarageQual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add target variable column 'qualAboveAverage' to dataframe \n",
    "# Specifies if house quality is above agerage (1) or below average(0)\n",
    "data['qualAboveAverage'] = (data['OverallQual'] > 5).astype(int)\n",
    "\n",
    "# Store target variable (qualAboveAverage) as y\n",
    "Y = data['qualAboveAverage']\n",
    "\n",
    "columns = data.columns \n",
    "columns_dtypes = data.dtypes\n",
    "numerical_types = [np.int64, np.int32, np.float32, np.float64]\n",
    "valid_col = [columns[i] for i in range(len(columns)) if columns_dtypes[i] in numerical_types]\n",
    "valid_data = pd.DataFrame(data, columns = valid_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverallQual: 0.784865736046\n",
      "YearBuilt: 0.479962376201\n",
      "YearRemodAdd: 0.437861757046\n",
      "ExterQual: 0.506235761975\n",
      "BsmtQual: 0.501488389632\n",
      "GrLivArea: 0.446058280118\n",
      "FullBath: 0.487962875878\n",
      "KitchenQual: 0.46337623216\n",
      "GarageCars: 0.469083851474\n",
      "SalePrice: 0.531738813349\n",
      "qualAboveAverage: 1.0\n"
     ]
    }
   ],
   "source": [
    "for column in valid_data.columns.values:\n",
    "    corr = abs(valid_data[column].corr(Y))\n",
    "    if corr > .4:\n",
    "        print(column + ':', corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Baseline Value: 0.631434454358\n"
     ]
    }
   ],
   "source": [
    "# Calculate the baseline for Logistic Regression model\n",
    "logit_baseline = max(Y.value_counts())/len(Y)\n",
    "print('Logistic Regression Baseline Value:', logit_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      YearBuilt  YearRemodAdd  BsmtQual  TotalBsmtSF  GrLivArea  FullBath  \\\n",
      "Id                                                                          \n",
      "1          2003          2003         5          856       1710         2   \n",
      "2          1976          1976         5         1262       1262         2   \n",
      "3          2001          2002         5          920       1786         2   \n",
      "4          1915          1970         4          756       1717         1   \n",
      "5          2000          2000         5         1145       2198         2   \n",
      "6          1993          1995         5          796       1362         1   \n",
      "7          2004          2005         6         1686       1694         2   \n",
      "8          1973          1973         5         1107       2090         2   \n",
      "9          1931          1950         4          952       1774         2   \n",
      "10         1939          1950         4          991       1077         1   \n",
      "11         1965          1965         4         1040       1040         1   \n",
      "12         2005          2006         6         1175       2324         3   \n",
      "13         1962          1962         4          912        912         1   \n",
      "14         2006          2007         5         1494       1494         2   \n",
      "15         1960          1960         4         1253       1253         1   \n",
      "16         1929          2001         4          832        854         1   \n",
      "17         1970          1970         4         1004       1004         1   \n",
      "18         1967          1967         1            0       1296         2   \n",
      "19         2004          2004         4         1114       1114         1   \n",
      "20         1958          1965         4         1029       1339         1   \n",
      "21         2005          2006         6         1158       2376         3   \n",
      "22         1930          1950         4          637       1108         1   \n",
      "23         2002          2002         5         1777       1795         2   \n",
      "24         1976          1976         5         1040       1060         1   \n",
      "25         1968          2001         4         1060       1060         1   \n",
      "26         2007          2007         5         1566       1600         2   \n",
      "27         1951          2000         4          900        900         1   \n",
      "28         2007          2008         6         1704       1704         2   \n",
      "29         1957          1997         4         1484       1600         1   \n",
      "30         1927          1950         4          520        520         1   \n",
      "...         ...           ...       ...          ...        ...       ...   \n",
      "1431       2005          2005         5          732       1838         2   \n",
      "1432       1976          1976         5          958        958         2   \n",
      "1433       1927          2007         4          656        968         2   \n",
      "1434       2000          2000         5          936       1792         2   \n",
      "1435       1977          1977         4         1126       1126         2   \n",
      "1436       1962          2005         4         1319       1537         1   \n",
      "1437       1971          1971         4          864        864         1   \n",
      "1438       2008          2008         6         1932       1932         2   \n",
      "1439       1957          1996         4          912       1236         1   \n",
      "1440       1979          1979         4          539       1725         2   \n",
      "1441       1922          1994         6          588       2555         2   \n",
      "1442       2004          2004         5          848        848         1   \n",
      "1443       2008          2008         6         1017       2007         2   \n",
      "1444       1916          1950         4          952        952         1   \n",
      "1445       2004          2004         5         1422       1422         2   \n",
      "1446       1966          1966         4          814        913         1   \n",
      "1447       1962          1962         4         1188       1188         1   \n",
      "1448       1995          1996         5         1220       2090         2   \n",
      "1449       1910          2000         3          560       1346         1   \n",
      "1450       1970          1970         5          630        630         1   \n",
      "1451       1974          1974         5          896       1792         2   \n",
      "1452       2008          2009         5         1573       1578         2   \n",
      "1453       2005          2005         5          547       1072         1   \n",
      "1454       2006          2006         5         1140       1140         1   \n",
      "1455       2004          2005         5         1221       1221         2   \n",
      "1456       1999          2000         5          953       1647         2   \n",
      "1457       1978          1988         5         1542       2073         2   \n",
      "1458       1941          2006         4         1152       2340         2   \n",
      "1459       1950          1996         4         1078       1078         1   \n",
      "1460       1965          1965         4         1256       1256         1   \n",
      "\n",
      "      KitchenQual  GarageCars  GarageArea  SalePrice  \n",
      "Id                                                    \n",
      "1               5           2         548     208500  \n",
      "2               4           2         460     181500  \n",
      "3               5           2         608     223500  \n",
      "4               5           3         642     140000  \n",
      "5               5           3         836     250000  \n",
      "6               4           2         480     143000  \n",
      "7               5           2         636     307000  \n",
      "8               4           2         484     200000  \n",
      "9               4           2         468     129900  \n",
      "10              4           1         205     118000  \n",
      "11              4           1         384     129500  \n",
      "12              6           3         736     345000  \n",
      "13              4           1         352     144000  \n",
      "14              5           3         840     279500  \n",
      "15              4           1         352     157000  \n",
      "16              4           2         576     132000  \n",
      "17              4           2         480     149000  \n",
      "18              4           2         516      90000  \n",
      "19              5           2         576     159000  \n",
      "20              4           1         294     139000  \n",
      "21              5           3         853     325300  \n",
      "22              5           1         280     139400  \n",
      "23              5           2         534     230000  \n",
      "24              4           2         572     129900  \n",
      "25              5           1         270     154000  \n",
      "26              5           3         890     256300  \n",
      "27              5           2         576     134800  \n",
      "28              5           3         772     306000  \n",
      "29              4           1         319     207500  \n",
      "30              3           1         240      68500  \n",
      "...           ...         ...         ...        ...  \n",
      "1431            4           2         372     192140  \n",
      "1432            4           2         440     143750  \n",
      "1433            4           1         216      64500  \n",
      "1434            4           2         451     186500  \n",
      "1435            4           2         484     160000  \n",
      "1436            5           2         462     174000  \n",
      "1437            4           2         528     120500  \n",
      "1438            6           3         774     394617  \n",
      "1439            4           2         923     149700  \n",
      "1440            4           2         550     197000  \n",
      "1441            4           2         672     191000  \n",
      "1442            5           2         420     149300  \n",
      "1443            6           3         812     310000  \n",
      "1444            3           1         192     121000  \n",
      "1445            5           2         626     179600  \n",
      "1446            4           1         240     129000  \n",
      "1447            4           1         312     157900  \n",
      "1448            5           2         556     240000  \n",
      "1449            4           1         384     112000  \n",
      "1450            6           0           0      92000  \n",
      "1451            4           0           0     136000  \n",
      "1452            6           3         840     287090  \n",
      "1453            4           2         525     145000  \n",
      "1454            4           0           0      84500  \n",
      "1455            5           2         400     185000  \n",
      "1456            4           2         460     175000  \n",
      "1457            4           2         500     210000  \n",
      "1458            5           1         252     266500  \n",
      "1459            5           1         240     142125  \n",
      "1460            4           1         276     147500  \n",
      "\n",
      "[1457 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#To choose appropriate features, correlation coeffient was used to choose columns. However, it did not yield  \n",
    "#a desirable output. Therefore, the method below was used to find suitable features.\n",
    "# Limit the feature set to intuitively relevant features \n",
    "#Houses that are newer are better quality; good neighborhood - better quality houses; better quality houses are \n",
    "#generally sold at higher prices.\n",
    "#relevant = ['YearRemodAdd', 'YearBuilt', 'MSZoning', 'Neighborhood','SalePrice', 'Condition1', 'Condition2']\n",
    "#X = data.filter(relevant)\n",
    "#X = data.drop(['OverallQual', 'qualAboveAverage', 'LandSlope', 'RoofStyle', 'Fireplaces'], axis=1)\n",
    "#X = data.drop('OverallQual', axis=1)\n",
    "#X = data.drop('qualAboveAverage', axis = 1)\n",
    "relevant = ['YearBuilt', 'YearRemodAdd', 'ExtreQul', 'BsmtQual', 'TotalBsmtSF', 'GrLivArea','FullBath', 'KitchenQual', 'GarageCars', 'GarageArea', 'SalePrice']        \n",
    "X = valid_data.filter(relevant)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "random_states = [98, 1560, 999, 105002, 77393]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Logistic Regression for a train-test-split of 0.9-0.1 has an accuracy score of:\n",
      "0.8425\n",
      "Thus, this model is 33.42% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The Logistic Regression for a train-test-split of 0.8-0.2 has an accuracy score of:\n",
      "0.8390\n",
      "Thus, this model is 32.88% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The Logistic Regression for a train-test-split of 0.7-0.3 has an accuracy score of:\n",
      "0.8151\n",
      "Thus, this model is 29.08% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The Logistic Regression for a train-test-split of 0.6-0.4 has an accuracy score of:\n",
      "0.8302\n",
      "Thus, this model is 31.48% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The Logistic Regression for a train-test-split of 0.5-0.5 has an accuracy score of:\n",
      "0.8258\n",
      "Thus, this model is 30.78% more accurate than the baseline model.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build model and fit on train set\n",
    "model = LogisticRegression()\n",
    "\n",
    "for i in range(0,5):\n",
    "    # Split dataset into training and test data\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=splits[i], random_state=random_states[i])\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, Y_train)\n",
    "    # Predict on the testing data\n",
    "    model.predict(X_test)\n",
    "    # Test the score of the model\n",
    "    score = model.score(X_test, Y_test)\n",
    "    # Calculate % improvement over the baseline\n",
    "    improvement = 100*(score - logit_baseline)/logit_baseline\n",
    "    print(\"The Logistic Regression for a train-test-split of {}-{} has an accuracy score of:\\n{:.4f}\"\n",
    "          .format(1-splits[i], splits[i], score))\n",
    "    print(\"Thus, this model is {:.2f}% more accurate than the baseline model.\"\n",
    "          .format(improvement))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
