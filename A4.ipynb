{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing_data = pd.DataFrame.from_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the baseline for linear regression\n",
    "prices = housing_data.filter(['SalePrice'])\n",
    "avg_price = prices.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the correlation coefficients for SalePrice with each of the other numerical features:\n",
      "\n",
      "1. MSSubClass: -0.08353247161509611\n",
      "2. LotFrontage: 0.209137300361708\n",
      "3. LotArea: 0.2639554484435689\n",
      "4. OverallQual: 0.7908701032855194\n",
      "5. OverallCond: -0.07747076838683664\n",
      "6. YearBuilt: 0.5229250946272646\n",
      "7. YearRemodAdd: 0.507087387087986\n",
      "8. BsmtFinSF1: 0.3858519610870544\n",
      "9. BsmtFinSF2: -0.013811048393577966\n",
      "10. BsmtUnfSF: 0.21285275404422782\n",
      "11. TotalBsmtSF: 0.6150306002600914\n",
      "12. 1stFlrSF: 0.6056811685298112\n",
      "13. 2ndFlrSF: 0.32045452502532046\n",
      "14. LowQualFinSF: -0.025516478206112737\n",
      "15. GrLivArea: 0.7088612518306577\n",
      "16. BsmtFullBath: 0.22645875233836776\n",
      "17. BsmtHalfBath: -0.01664413437848131\n",
      "18. FullBath: 0.5606660611742326\n",
      "19. HalfBath: 0.2853242963661683\n",
      "20. BedroomAbvGr: 0.16817449421857766\n",
      "21. KitchenAbvGr: -0.13580936177277597\n",
      "22. TotRmsAbvGrd: 0.5338292886465191\n",
      "23. Fireplaces: 0.46676213136684097\n",
      "24. GarageCars: 0.6399663562678245\n",
      "25. GarageArea: 0.622866688949611\n",
      "26. WoodDeckSF: 0.3253222286666081\n",
      "27. OpenPorchSF: 0.31668309318470195\n",
      "28. EnclosedPorch: -0.1283569455926468\n",
      "29. 3SsnPorch: 0.04471266204919867\n",
      "30. ScreenPorch: 0.11175782951631341\n",
      "31. PoolArea: 0.09251910934881503\n",
      "32. MiscVal: -0.02112558702571772\n",
      "33. MoSold: 0.04542523813048607\n",
      "34. YrSold: -0.029607572241981787\n",
      "\n",
      "Below are the columns (and correlation coefficients) that have been deemed significant (absolute coefficient >= 0.5) and will be used in the linear regression model\n",
      "1. OverallQual: 0.7908701032855194\n",
      "2. YearBuilt: 0.5229250946272646\n",
      "3. YearRemodAdd: 0.507087387087986\n",
      "4. TotalBsmtSF: 0.6150306002600914\n",
      "5. 1stFlrSF: 0.6056811685298112\n",
      "6. GrLivArea: 0.7088612518306577\n",
      "7. FullBath: 0.5606660611742326\n",
      "8. TotRmsAbvGrd: 0.5338292886465191\n",
      "9. GarageCars: 0.6399663562678245\n",
      "10. GarageArea: 0.622866688949611\n"
     ]
    }
   ],
   "source": [
    "# Identify the relevant features\n",
    "\n",
    "columns = housing_data.columns\n",
    "column_dtypes = housing_data.dtypes\n",
    "numerical_types = [np.int64, np.int32, np.float32, np.float64]\n",
    "\n",
    "valid_col = [columns[i] for i in range(len(columns)) if column_dtypes[i] in numerical_types]\n",
    "X = pd.DataFrame(housing_data, columns = valid_col)\n",
    "corr = np.corrcoef(X, rowvar=False)\n",
    "\n",
    "# Get SalePrice corrcoef with everything else\n",
    "sale_price_corr_coef = corr[-1][:-1]\n",
    "\n",
    "significant_col = []\n",
    "significant_col_values = []\n",
    "sig_threshold = 0.5 # arbitrarily setting it at >=0.5\n",
    "print(\"Below is the correlation coefficients for SalePrice with each of the other numerical features:\\n\")\n",
    "for i in range(len(sale_price_corr_coef)):\n",
    "    corr_coef = sale_price_corr_coef[i]\n",
    "    print(\"{}. {}: {}\".format(i+1, valid_col[i], corr_coef))\n",
    "    if abs(corr_coef) >= sig_threshold:\n",
    "        significant_col.append(valid_col[i])\n",
    "        significant_col_values.append(corr_coef)\n",
    "\n",
    "print(\"\\nBelow are the columns (and correlation coefficients) that have been deemed significant (absolute coefficient >= 0.5) and will be used \" +\n",
    "      \"in the linear regression model\")\n",
    "\n",
    "for i in range(len(significant_col)):\n",
    "    print(\"{}. {}: {}\".format(i+1, significant_col[i], significant_col_values[i]))\n",
    "    \n",
    "feature_set = housing_data.filter(significant_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "random_states = [42, 1337, 420, 90210, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_and_test_model(dataset, target, test_size, seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, target, test_size = test_size, random_state=seed)\n",
    "    model = LinearRegression()\n",
    "    model = model.fit(X=X_train, y=y_train)\n",
    "    predictions = model.predict(X=X_test)\n",
    "    MSE = sklearn.metrics.mean_squared_error(y_true = y_test, y_pred = predictions)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    num_targets = len(y_test)\n",
    "    baseline_pred = [avg_price] * num_targets\n",
    "    BaselineMSE = sklearn.metrics.mean_squared_error(y_true = y_test, y_pred = baseline_pred)\n",
    "    BaselineRMSE = np.sqrt(BaselineMSE)\n",
    "    return model, RMSE, BaselineRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create and test model for linear regression for 5 different train_test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the split 0.1 is 31899.34418813559\n",
      "This model performs 59.70% better than the baseline model\n",
      "\n",
      "\n",
      "The RMSE for the split 0.2 is 34524.61572284951\n",
      "This model performs 55.12% better than the baseline model\n",
      "\n",
      "\n",
      "The RMSE for the split 0.3 is 41071.365101906216\n",
      "This model performs 45.40% better than the baseline model\n",
      "\n",
      "\n",
      "The RMSE for the split 0.4 is 38010.686585263145\n",
      "This model performs 54.15% better than the baseline model\n",
      "\n",
      "\n",
      "The RMSE for the split 0.5 is 42517.341371332455\n",
      "This model performs 47.46% better than the baseline model\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    test_size = splits[i]\n",
    "    seed = random_states[i]\n",
    "    model, RMSE, BaselineRMSE = create_and_test_model(feature_set, prices, test_size, seed)\n",
    "    print(\"The RMSE for the split {} is {}\".format(test_size, RMSE))\n",
    "    improvement = (BaselineRMSE - RMSE) * 100 / BaselineRMSE \n",
    "    print(\"This model performs {:.2f}% better than the baseline model\".format(improvement))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add column 'After1970' to dataframe to specify if house was built after 1970 (True) or before (False)\n",
    "housing_data['After1970'] = housing_data['YearBuilt'] > 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Baseline Value: 0.530542210021\n"
     ]
    }
   ],
   "source": [
    "#Baseline for KNN:\n",
    "#This should be the value that is most common in the dependent variable.\n",
    "baseline = (housing_data['After1970'].describe()['freq'])/(housing_data['After1970'].describe()['count'])\n",
    "print('KNN Baseline Value:', baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create and test KNN model for 5 different train_test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine strength of correlation for features of interest\n",
    "# X = pd.DataFrame(housing_data,columns=['YearRemodAdd', 'OverallQual', 'GarageCars','YearBuilt']) \n",
    "# corr = np.corrcoef(X,rowvar=False) #rowvar = False b/c columns are features\n",
    "# print (corr)\n",
    "\n",
    "# Identify the relevant features\n",
    "KNN_relevant_features = ['YearRemodAdd', 'OverallQual', 'GarageCars']\n",
    "\n",
    "# Normalize relevant features to between 0 and 1 for KNN distance calculation\n",
    "KNN_feature_set = housing_data.filter(KNN_relevant_features)\n",
    "KNN_feature_set['YearRemodAdd'] = (KNN_feature_set['YearRemodAdd'] - KNN_feature_set['YearRemodAdd'].min())/(KNN_feature_set['YearRemodAdd'].max() - KNN_feature_set['YearRemodAdd'].min())\n",
    "KNN_feature_set['OverallQual'] = (KNN_feature_set['OverallQual'] - KNN_feature_set['OverallQual'].min())/(KNN_feature_set['OverallQual'].max() - KNN_feature_set['OverallQual'].min())\n",
    "KNN_feature_set['GarageCars'] = (KNN_feature_set['GarageCars'] - KNN_feature_set['GarageCars'].min())/(KNN_feature_set['GarageCars'].max() - KNN_feature_set['GarageCars'].min())\n",
    "\n",
    "After1970 = housing_data.filter(['After1970'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations with YearBuilt are as follows: YearRemodAdd (.59), OverallQual (.57), GarageCars (.54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_test_KNN_model(dataset, target, test_size, seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, target, test_size = test_size, random_state=seed)\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    model = model.fit(X=X_train, y=y_train)\n",
    "    predictions = model.predict(X=X_test)\n",
    "    confusion = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    return model, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for split 0.1 is: \n",
      " [[279  56]\n",
      " [ 27 367]]\n",
      "This model performs 67.03% better than the baseline model\n",
      "\n",
      "\n",
      "Confusion matrix for split 0.2 is: \n",
      " [[298  43]\n",
      " [ 25 363]]\n",
      "This model performs 70.90% better than the baseline model\n",
      "\n",
      "\n",
      "Confusion matrix for split 0.3 is: \n",
      " [[295  55]\n",
      " [ 23 356]]\n",
      "This model performs 68.32% better than the baseline model\n",
      "\n",
      "\n",
      "Confusion matrix for split 0.4 is: \n",
      " [[310  42]\n",
      " [ 32 345]]\n",
      "This model performs 69.35% better than the baseline model\n",
      "\n",
      "\n",
      "Confusion matrix for split 0.5 is: \n",
      " [[299  42]\n",
      " [ 43 345]]\n",
      "This model performs 66.51% better than the baseline model\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use same splits as in linear regression above\n",
    "#ravel converts column to 1_D array (avoids a data type conversion warning)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    test_size = splits[i] \n",
    "    seed = random_states[i]\n",
    "    model, confusion = create_and_test_KNN_model(KNN_feature_set, np.ravel(After1970), split, seed)\n",
    "    print(\"Confusion matrix for split {} is: \\n {}\".format(test_size, confusion))\n",
    "    TP = confusion[0,0]\n",
    "    FN = confusion[1,0]\n",
    "    FP = confusion[0,1]\n",
    "    TN = confusion[1,1]\n",
    "    accuracy = (TP + TN)/(TP + FN + FP + TN)\n",
    "    improvement = (accuracy - baseline) * 100 / baseline \n",
    "    print(\"This model performs {:.2f}% better than the baseline model\".format(improvement))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
