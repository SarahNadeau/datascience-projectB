{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, preprocessing, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import cleaned dataset from last project - https://github.com/SarahNadeau/datascience-projectB/blob/master/cleaned.csv\n",
    "data = pd.DataFrame.from_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NAmes': 225, 'CollgCr': 149, 'OldTown': 113, 'Edwards': 100, 'Somerst': 86, 'Gilbert': 79, 'NridgHt': 76, 'Sawyer': 74, 'NWAmes': 73, 'SawyerW': 59, 'BrkSide': 58, 'Crawfor': 51, 'Mitchel': 49, 'NoRidge': 41, 'IDOTRR': 37, 'Timber': 37, 'ClearCr': 28, 'StoneBr': 25, 'SWISU': 25, 'MeadowV': 17, 'Blmngtn': 17, 'BrDale': 16, 'Veenker': 11, 'NPkVill': 9, 'Blueste': 2})\n",
      "Number of Neighborhood types: 25\n",
      "Baseline accuracy: 0.15442690459849004\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Model\n",
    "# Take a look at the target variable distribution and calculate baseline\n",
    "c = Counter(data['Neighborhood'])\n",
    "num_col = len(c)\n",
    "baseline = max(c.values()) / sum(c.values())\n",
    "print(c)\n",
    "print(\"Number of Neighborhood types: \" + str(num_col))\n",
    "print(\"Baseline accuracy: \" + str(baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode the dataset with labels\n",
    "enc = LabelEncoder()\n",
    "\n",
    "for i in data.columns:\n",
    "    data[i] = enc.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store target variable (Neighborhood) as y\n",
    "y = data['Neighborhood']\n",
    "X = data.drop('Neighborhood', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "random_states = [421, 1337, 420, 90210, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_and_test_decision_tree(dataset, target, test_size, seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, target, test_size = test_size, random_state=seed)\n",
    "    model = DecisionTreeClassifier(max_leaf_nodes=100)\n",
    "    model = model.fit(X=X_train, y=y_train)\n",
    "    with open(\"decisiontree.txt\", 'w') as f:\n",
    "        export_graphviz(model, out_file=f, feature_names=list(X))\n",
    "    tree_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_true = y_test, y_pred = tree_pred)\n",
    "    percent_imprv = 100 * (score - baseline) / baseline \n",
    "    return model, score, percent_imprv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree for the train-test-split of 0.9-0.1 has an accuracy score of:\n",
      "0.547945205479452\n",
      "Thus, this model is 254.82% more accurate than the baseline model\n",
      "\n",
      "\n",
      "The decision tree for the train-test-split of 0.8-0.2 has an accuracy score of:\n",
      "0.5547945205479452\n",
      "Thus, this model is 259.26% more accurate than the baseline model\n",
      "\n",
      "\n",
      "The decision tree for the train-test-split of 0.7-0.3 has an accuracy score of:\n",
      "0.58675799086758\n",
      "Thus, this model is 279.96% more accurate than the baseline model\n",
      "\n",
      "\n",
      "The decision tree for the train-test-split of 0.6-0.4 has an accuracy score of:\n",
      "0.48027444253859347\n",
      "Thus, this model is 211.00% more accurate than the baseline model\n",
      "\n",
      "\n",
      "The decision tree for the train-test-split of 0.5-0.5 has an accuracy score of:\n",
      "0.48148148148148145\n",
      "Thus, this model is 211.79% more accurate than the baseline model\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test Decision Tree Classifierfor 5 different train_test splits\n",
    "for i in range(5):\n",
    "    test_size = splits[i]\n",
    "    seed = random_states[i]\n",
    "    model, score, imprv = create_and_test_decision_tree(X, y, test_size, seed)\n",
    "    print(\"The decision tree for the train-test-split of {}-{} has an accuracy score of:\\n{}\"\n",
    "          .format(1-test_size, test_size, score))\n",
    "    print(\"Thus, this model is {:.2f}% more accurate than the baseline model\".format(imprv))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store the target variable (HouseStyle) as Y - and encode its labels\n",
    "data = pd.DataFrame.from_csv('cleaned.csv')\n",
    "\n",
    "Y = data['HouseStyle']\n",
    "\n",
    "encodings = {'1Story': 1, '1.5Unf': 2, '1.5Fin': 3, '2Story': 4, '2.5Unf': 5, '2.5Fin': 6, 'SFoyer': 7, 'SLvl': 8}\n",
    "for key in encodings:\n",
    "    Y = Y.replace(key, encodings[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform feature engineering to determine features to include\n",
    "X = pd.DataFrame()\n",
    "\n",
    "data = pd.DataFrame.from_csv('cleaned.csv')\n",
    "\n",
    "columns = data.columns\n",
    "column_dtypes = data.dtypes\n",
    "numerical_types = [np.int64, np.int32, np.float32, np.float64]\n",
    "valid_col = [columns[i] for i in range(len(columns)) if column_dtypes[i] in numerical_types]\n",
    "valid_data = pd.DataFrame(data, columns = valid_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM baseline value: 0.497597803706\n"
     ]
    }
   ],
   "source": [
    "# Calculate the baseline for SVM\n",
    "SVM_baseline = max(Y.value_counts())/len(Y)\n",
    "print('SVM baseline value:', SVM_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass: 0.47217525491\n",
      "2ndFlrSF: 0.546533790195\n"
     ]
    }
   ],
   "source": [
    "# Assign features with strong correlation to target variable to feature set X \n",
    "# Correlation cutoff arbitrarily set to .4\n",
    "\n",
    "for column in valid_data.columns.values:\n",
    "    corr = abs(valid_data[column].corr(Y))\n",
    "    if corr > .4:\n",
    "        print(column + ':', corr)\n",
    "        X[column] = valid_data[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement SVM model with default settings (RBF kerenel) \n",
    "model = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SVM for a train-test-split of 0.9-0.1 has an accuracy score of:\n",
      "0.8973\n",
      "Thus, this model is 80.32% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The SVM for a train-test-split of 0.8-0.2 has an accuracy score of:\n",
      "0.9110\n",
      "Thus, this model is 83.07% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The SVM for a train-test-split of 0.7-0.3 has an accuracy score of:\n",
      "0.8904\n",
      "Thus, this model is 78.94% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The SVM for a train-test-split of 0.6-0.4 has an accuracy score of:\n",
      "0.8834\n",
      "Thus, this model is 77.53% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The SVM for a train-test-split of 0.5-0.5 has an accuracy score of:\n",
      "0.8765\n",
      "Thus, this model is 76.15% more accurate than the baseline model.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=splits[i], random_state=random_states[i])\n",
    "    model.fit(X_train, Y_train)\n",
    "    model.predict(X_test)\n",
    "    score = model.score(X_test, Y_test)\n",
    "    improvement = 100*(score - SVM_baseline)/SVM_baseline\n",
    "    print(\"The SVM for a train-test-split of {}-{} has an accuracy score of:\\n{:.4f}\"\n",
    "          .format(1-splits[i], splits[i], score))\n",
    "    print(\"Thus, this model is {:.2f}% more accurate than the baseline model.\"\n",
    "          .format(improvement))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cleaned dataset from last project\n",
    "data = pd.DataFrame.from_csv('cleaned.csv')\n",
    "\n",
    "BsmtQual = data['BsmtQual']\n",
    "encodings = {'Ex': 6, 'Gd': 5, 'TA': 4, 'Fa': 3, 'Po': 2, 'NP' :1}\n",
    "for key in encodings:\n",
    "    BsmtQual = BsmtQual.replace(key, encodings[key])\n",
    "data['BsmtQual'] = BsmtQual\n",
    "    \n",
    "ExterQual = data['ExterQual']\n",
    "encodings = {'Ex': 6, 'Gd': 5, 'TA': 4, 'Fa': 3, 'Po': 2, 'NP' :1}\n",
    "for key in encodings:\n",
    "    ExterQual = ExterQual.replace(key, encodings[key])\n",
    "data['ExterQual'] = ExterQual\n",
    "    \n",
    "ExterCond = data['ExterCond']\n",
    "encodings = {'Ex': 6, 'Gd': 5, 'TA': 4, 'Fa': 3, 'Po': 2, 'NP' :1}\n",
    "for key in encodings:\n",
    "    ExterCond = ExterCond.replace(key, encodings[key])\n",
    "data['ExterCond'] = ExterCond\n",
    "    \n",
    "BsmtCond = data['BsmtCond']\n",
    "encodings = {'Ex': 6, 'Gd': 5, 'TA': 4, 'Fa': 3, 'Po': 2, 'NP' :1}\n",
    "for key in encodings:\n",
    "    BsmtCond = BsmtCond.replace(key, encodings[key])\n",
    "data['BsmtCond'] = BsmtCond\n",
    "    \n",
    "KitchenQual = data['KitchenQual']\n",
    "encodings = {'Ex': 6, 'Gd': 5, 'TA': 4, 'Fa': 3, 'Po': 2, 'NP' :1}\n",
    "for key in encodings:\n",
    "    KitchenQual = KitchenQual.replace(key, encodings[key])\n",
    "data['KitchenQual'] = KitchenQual\n",
    "    \n",
    "GarageQual = data['GarageQual']\n",
    "encodings = {'Ex': 6, 'Gd': 5, 'TA': 4, 'Fa': 3, 'Po': 2, 'NP' :1}\n",
    "for key in encodings:\n",
    "    GarageQual = GarageQual.replace(key, encodings[key])\n",
    "data['GarageQual'] = GarageQual\n",
    "\n",
    "encoded = ['BsmtQual', 'ExterQual', 'ExterCond', 'BsmtCond', 'KitchenQual', 'GarageQual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store target variable (qualAboveAverage) as y \n",
    "# Specifies if house quality is above agerage (1) or below average(0)\n",
    "Y = (data['OverallQual'] > 5).astype(int)\n",
    "\n",
    "columns = data.columns \n",
    "columns_dtypes = data.dtypes\n",
    "numerical_types = [np.int64, np.int32, np.float32, np.float64]\n",
    "valid_col = [columns[i] for i in range(len(columns)) if columns_dtypes[i] in numerical_types]\n",
    "valid_col.remove('OverallQual')\n",
    "valid_data = pd.DataFrame(data, columns = valid_col)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "for i in valid_data.columns:\n",
    "    valid_data[i] = enc.fit_transform(valid_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearBuilt: 0.493020979675\n",
      "YearRemodAdd: 0.437861757046\n",
      "ExterQual: 0.506235761975\n",
      "BsmtQual: 0.521354932126\n",
      "GrLivArea: 0.490761427974\n",
      "FullBath: 0.487962875878\n",
      "KitchenQual: 0.46337623216\n",
      "GarageCars: 0.469083851474\n",
      "SalePrice: 0.636310119244\n"
     ]
    }
   ],
   "source": [
    "for column in valid_data.columns.values:\n",
    "    corr = abs(valid_data[column].corr(Y))\n",
    "    if corr > .4:\n",
    "        print(column + ':', corr)\n",
    "        X[column] = valid_data[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Baseline Value: 0.631434454358\n"
     ]
    }
   ],
   "source": [
    "# Calculate the baseline for Logistic Regression model\n",
    "logit_baseline = max(Y.value_counts())/len(Y)\n",
    "print('Logistic Regression Baseline Value:', logit_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Logistic Regression for a train-test-split of 0.9-0.1 has an accuracy score of:\n",
      "0.8288\n",
      "Thus, this model is 31.25% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The Logistic Regression for a train-test-split of 0.8-0.2 has an accuracy score of:\n",
      "0.8425\n",
      "Thus, this model is 33.42% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The Logistic Regression for a train-test-split of 0.7-0.3 has an accuracy score of:\n",
      "0.8425\n",
      "Thus, this model is 33.42% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The Logistic Regression for a train-test-split of 0.6-0.4 has an accuracy score of:\n",
      "0.8508\n",
      "Thus, this model is 34.74% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The Logistic Regression for a train-test-split of 0.5-0.5 has an accuracy score of:\n",
      "0.8244\n",
      "Thus, this model is 30.56% more accurate than the baseline model.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build model and fit on train set\n",
    "model = LogisticRegression()\n",
    "\n",
    "for i in range(0,5):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=splits[i], random_state=random_states[i])\n",
    "    model.fit(X_train, Y_train)\n",
    "    score = model.score(X_test, Y_test)\n",
    "    improvement = 100*(score - logit_baseline)/logit_baseline\n",
    "    print(\"The Logistic Regression for a train-test-split of {}-{} has an accuracy score of:\\n{:.4f}\"\n",
    "          .format(1-splits[i], splits[i], score))\n",
    "    print(\"Thus, this model is {:.2f}% more accurate than the baseline model.\"\n",
    "          .format(improvement))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
