{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, preprocessing, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import cleaned dataset from last project - https://github.com/SarahNadeau/datascience-projectB/blob/master/cleaned.csv\n",
    "data = pd.DataFrame.from_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NAmes': 225, 'CollgCr': 149, 'OldTown': 113, 'Edwards': 100, 'Somerst': 86, 'Gilbert': 79, 'NridgHt': 76, 'Sawyer': 74, 'NWAmes': 73, 'SawyerW': 59, 'BrkSide': 58, 'Crawfor': 51, 'Mitchel': 49, 'NoRidge': 41, 'IDOTRR': 37, 'Timber': 37, 'ClearCr': 28, 'StoneBr': 25, 'SWISU': 25, 'MeadowV': 17, 'Blmngtn': 17, 'BrDale': 16, 'Veenker': 11, 'NPkVill': 9, 'Blueste': 2})\n",
      "Number of Neighborhood types: 25\n",
      "Baseline accuracy: 0.15442690459849004\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Model\n",
    "# Take a look at the target variable distribution and calculate baseline\n",
    "c = Counter(data['Neighborhood'])\n",
    "num_col = len(c)\n",
    "baseline = max(c.values()) / sum(c.values())\n",
    "print(c)\n",
    "print(\"Number of Neighborhood types: \" + str(num_col))\n",
    "print(\"Baseline accuracy: \" + str(baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode the dataset with labels\n",
    "enc = LabelEncoder()\n",
    "\n",
    "for i in data.columns:\n",
    "    data[i] = enc.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store target variable (Neighborhood) as y\n",
    "y = data['Neighborhood']\n",
    "X = data.drop('Neighborhood', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "random_states = [42, 1337, 420, 90210, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_and_test_decision_tree(dataset, target, test_size, seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, target, test_size = test_size, random_state=seed)\n",
    "    model = DecisionTreeClassifier(max_leaf_nodes=100)\n",
    "    model = model.fit(X=X_train, y=y_train)\n",
    "    with open(\"decisiontree.txt\", 'w') as f:\n",
    "        export_graphviz(model, out_file=f, feature_names=list(X))\n",
    "    tree_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_true = y_test, y_pred = tree_pred)\n",
    "    percent_imprv = 100 * (score - baseline) / baseline \n",
    "    return model, score, percent_imprv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree for the train-test-split of 0.9-0.1 has an accuracy score of:\n",
      "0.5958904109589042\n",
      "Thus, this model is 285.87% more accurate than the baseline model\n",
      "\n",
      "\n",
      "The decision tree for the train-test-split of 0.8-0.2 has an accuracy score of:\n",
      "0.547945205479452\n",
      "Thus, this model is 254.82% more accurate than the baseline model\n",
      "\n",
      "\n",
      "The decision tree for the train-test-split of 0.7-0.3 has an accuracy score of:\n",
      "0.593607305936073\n",
      "Thus, this model is 284.39% more accurate than the baseline model\n",
      "\n",
      "\n",
      "The decision tree for the train-test-split of 0.6-0.4 has an accuracy score of:\n",
      "0.4734133790737564\n",
      "Thus, this model is 206.56% more accurate than the baseline model\n",
      "\n",
      "\n",
      "The decision tree for the train-test-split of 0.5-0.5 has an accuracy score of:\n",
      "0.5116598079561042\n",
      "Thus, this model is 231.33% more accurate than the baseline model\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test Decision Tree Classifierfor 5 different train_test splits\n",
    "for i in range(5):\n",
    "    test_size = splits[i]\n",
    "    seed = random_states[i]\n",
    "    model, score, imprv = create_and_test_decision_tree(X, y, test_size, seed)\n",
    "    print(\"The decision tree for the train-test-split of {}-{} has an accuracy score of:\\n{}\"\n",
    "          .format(1-test_size, test_size, score))\n",
    "    print(\"Thus, this model is {:.2f}% more accurate than the baseline model\".format(imprv))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store the target variable (HouseStyle) as Y\n",
    "Y = data['HouseStyle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM baseline value: 0.497597803706\n"
     ]
    }
   ],
   "source": [
    "# Calculate the baseline for SVM\n",
    "SVM_baseline = max(Y.value_counts())/len(Y)\n",
    "print('SVM baseline value:', SVM_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass: 0.445623148876\n",
      "2ndFlrSF: 0.510942821246\n",
      "HalfBath: 0.413121689392\n"
     ]
    }
   ],
   "source": [
    "# Perform feature engineering to determine features to include\n",
    "X = pd.DataFrame()\n",
    "\n",
    "# Assign features with strong correlation to target variable to feature set X \n",
    "# Correlation cutoff arbitrarily set to .4\n",
    "for column in data.columns.values:\n",
    "    if (abs(data[column].corr(data['HouseStyle'])) > .4 and column != 'HouseStyle'):\n",
    "        print(column + ':', data[column].corr(data['HouseStyle']))\n",
    "        X[column] = data[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement SVM model with default settings (RBF kerenel) \n",
    "model = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SVM for a train-test-split of 0.9-0.1 has an accuracy score of:\n",
      "0.9247\n",
      "Thus, this model is 85.82% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The SVM for a train-test-split of 0.8-0.2 has an accuracy score of:\n",
      "0.9281\n",
      "Thus, this model is 86.51% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The SVM for a train-test-split of 0.7-0.3 has an accuracy score of:\n",
      "0.9087\n",
      "Thus, this model is 82.61% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The SVM for a train-test-split of 0.6-0.4 has an accuracy score of:\n",
      "0.9057\n",
      "Thus, this model is 82.01% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The SVM for a train-test-split of 0.5-0.5 has an accuracy score of:\n",
      "0.8930\n",
      "Thus, this model is 79.46% more accurate than the baseline model.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=splits[i], random_state=random_states[i])\n",
    "    model.fit(X_train, Y_train)\n",
    "    model.predict(X_test)\n",
    "    score = model.score(X_test, Y_test)\n",
    "    improvement = 100*(score - SVM_baseline)/SVM_baseline\n",
    "    print(\"The SVM for a train-test-split of {}-{} has an accuracy score of:\\n{:.4f}\"\n",
    "          .format(1-splits[i], splits[i], score))\n",
    "    print(\"Thus, this model is {:.2f}% more accurate than the baseline model.\"\n",
    "          .format(improvement))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cleaned dataset from last project\n",
    "data = pd.DataFrame.from_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Baseline Value: 0.631434454358\n"
     ]
    }
   ],
   "source": [
    "# Add target variable column 'qualAboveAverage' to dataframe \n",
    "# Specifies if house quality is above average (1) or below average(0)\n",
    "Y = (data['OverallQual'] > 5).astype(int)\n",
    "\n",
    "X = pd.DataFrame()\n",
    "logit_baseline = max(Y.value_counts())/len(Y)\n",
    "print('Logistic Regression Baseline Value:', logit_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'TA': 649, 'Gd': 615, 'Ex': 121, 'NP': 37, 'Fa': 35})\n",
      "Counter({4: 649, 2: 615, 0: 121, 3: 37, 1: 35})\n",
      "YearBuilt: 0.493020979675\n",
      "YearRemodAdd: 0.437861757046\n",
      "ExterQual: 0.415983469238\n",
      "BsmtQual: 0.453880347052\n",
      "GrLivArea: 0.490761427974\n",
      "FullBath: 0.487962875878\n",
      "GarageCars: 0.469083851474\n",
      "SalePrice: 0.636310119244\n"
     ]
    }
   ],
   "source": [
    "print(Counter(data['BsmtQual']))\n",
    "enc = LabelEncoder()\n",
    "for i in data.columns:\n",
    "    data[i] = enc.fit_transform(data[i])\n",
    "data = data.drop(\"OverallQual\",axis=1)\n",
    "print(Counter(data['BsmtQual']))\n",
    "\n",
    "for column in data.columns.values:\n",
    "    corr = abs(data[column].corr(Y))\n",
    "    if corr > .4:\n",
    "        print(column + ':', corr)\n",
    "        X[column] = data[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Logistic Regression for a train-test-split of 0.9-0.1 has an accuracy score of:\n",
      "0.8699\n",
      "Thus, this model is 37.76% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The Logistic Regression for a train-test-split of 0.8-0.2 has an accuracy score of:\n",
      "0.8527\n",
      "Thus, this model is 35.05% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The Logistic Regression for a train-test-split of 0.7-0.3 has an accuracy score of:\n",
      "0.8425\n",
      "Thus, this model is 33.42% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The Logistic Regression for a train-test-split of 0.6-0.4 has an accuracy score of:\n",
      "0.8439\n",
      "Thus, this model is 33.65% more accurate than the baseline model.\n",
      "\n",
      "\n",
      "The Logistic Regression for a train-test-split of 0.5-0.5 has an accuracy score of:\n",
      "0.8326\n",
      "Thus, this model is 31.87% more accurate than the baseline model.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=splits[i], random_state=random_states[i])\n",
    "    model.fit(X_train, Y_train)\n",
    "    score = model.score(X_test, Y_test)\n",
    "    # Calculate % improvement over the baseline\n",
    "    improvement = 100*(score - logit_baseline)/logit_baseline\n",
    "    print(\"The Logistic Regression for a train-test-split of {}-{} has an accuracy score of:\\n{:.4f}\"\n",
    "          .format(1-splits[i], splits[i], score))\n",
    "    print(\"Thus, this model is {:.2f}% more accurate than the baseline model.\"\n",
    "          .format(improvement))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
